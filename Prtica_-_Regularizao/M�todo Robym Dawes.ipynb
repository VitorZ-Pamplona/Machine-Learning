{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdMfcB0SnpXzFIkp6bGZpa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sKPfuEnapDnU"},"source":["# <font color=\"darkblue\"> Método Linear Imprópio</font>"]},{"cell_type":"markdown","metadata":{"id":"nKa5whanpntS"},"source":["Em 1974, o psicologo Robym Dawes propôs o *metodo linear imprópio*, em vez de usar a regressão multipla (linear) para determinar o peso preciso de cada variável preditora, ele propôs atribuir pesos iguais a todas elas.\n","\n","**Correlação de validação cruzada:** para um modelo de classificação ser bem-sucedido sua medida de precisão deve ser eficaz em uma nova amostra (teste), diferente da amostra original (treino) onde os pesos foram induzidos. \n","\n","Dawes propôs a previsão da média escolar de 90 alunos do primeiro ano da pós-graduação em Psicologia na Universidade de Ilinois. Foram utilizadas 10 variáveis ligadas a sucesso acadêmico: notas, extroversão, integridade, pontos em teste de apitidão e etc.\n","O modelo de regressão linear multipla obteve $E_{in}=25\\%$ (treino) e $E_{out}=31\\%$ (teste). Já o *modelo linear imprópio* obteve $E_{in}$ e $E_{out}$ praticamente iguais com valor de 30%, pela correlação de validação cruzada melhor que a regressão linear múltipla. Isto ocorreu em vários outros estudos realizados por Dawes. O que está acontecendo nestes casos??\n","\n","**Condições para o método linear imprópio ser melhor que a regressão linear:**\n","\n","\n","1.   Usar variáveis preditoras correlacionadas de forma confiável com o resultado;  \n","\n","2.   As variáveis preditoras tem que está normalizadas;\n","\n","3.   Amostra original pequena. A precisão na validação cruzada diminui por causa do peso dos acasos (ruídos) que fica maior em amostras pequenas. Nas ciências sociais as amostras são geralmente pequenas.\n","\n","\n","\n","**Objetivos:**\n","\n","*   Comparar o resultado do modelo proposto por Robym Dawes com a regressão logística em um dataset de classificação de risco de ataque cardíaco;\n","*   Identificar como resolver o problema nos erros de classificação de modelos de aprendizado.\n","\n","**Requisitos de execução:**\n","\n","\n","*   Upload do arquivo *heart_failure_clinical_records_dataset.csv*"]},{"cell_type":"markdown","metadata":{"id":"OPCbV-Udr1Pz"},"source":["**Atividade 1:**\n","\n","1. Carregar os dados do arquivo *heart_failure_clinical_records_dataset.csv* utilizando o pandas.\n","\n","    "]},{"cell_type":"code","metadata":{"id":"ZROjmwlFocyd"},"source":["import pandas as pd\n","import numpy as np\n","\n","heart_data = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n","print(heart_data.head())\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Atividade 2:**\n","\n","1. Plotar o quadro de correlações entre as variáveis preditoras e o rótulo a ser aprendido."],"metadata":{"id":"OF92WxEVV0yR"}},{"cell_type":"code","source":["import seaborn as sn\n","\n","correlation = heart_data.corr()\n","plot = sn.heatmap(correlation, annot = True, fmt=\".1f\", linewidths=.6)\n","plot"],"metadata":{"id":"B6l3NPJ0A9Nj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O73AMlZRtOTU"},"source":["**Atividade 3:**\n","\n","1. Extrair do *Dataframe* as variáveis preditoras com correlação baixa ao rótulo;\n","2. Construir a matriz de amostras *X* e o vetor de rótulos *y* ([\"DEATH_EVENT\"]);\n","3. Pegar 50% dos dados aleatoriamente para criar uma amostra pequena;\n","4. Dividir os dados em treino (80%) e teste (20%);\n","5. Normalizar os dados. As amostras de teste devem ser normalizadas separadas dos dados de treino com os valores min/max obtidos nos dados do treino. Evita bisbilhotagem dos dados.\n"]},{"cell_type":"code","metadata":{"id":"sU9ugDeOtaHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680542541148,"user_tz":180,"elapsed":484,"user":{"displayName":"Gilberto Farias","userId":"08659255523274913012"}},"outputId":"fbb98131-90ba-47c3-b18d-d6f491d5265c"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","Features = ['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']\n","\n","x = heart_data[Features].values\n","y = heart_data[\"DEATH_EVENT\"].values\n","y = [+1 if y_ == 1 else -1 for y_ in y]\n","\n","x, _, y, _ = train_test_split(x,y, test_size=0.5, random_state=38)\n","x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=10)\n","\n","mms = MinMaxScaler()\n","mms.fit(x_train)\n","x_test = mms.transform(x_test)\n","x_train = mms.transform(x_train)\n","\n","print(\"Tamanho treinamento: \" + str(len(x_train)))\n","print(\"Tamanho teste: \" + str(len(x_test)))\n","\n","#print(x_test)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Tamanho treinamento: 111\n","Tamanho teste: 38\n"]}]},{"cell_type":"markdown","metadata":{"id":"0SH_p2JeTmEN"},"source":["**Atividade 4:**\n","\n","1. Utilizar a classe LogisticRegression do pacote *sklearn.metrics* para induzir os pesos associado a cada variável preditora. Utilize para isto os dados de treino;\n","2. Compute e compare os valores de $E_{in}$ e $E_{out}$ (validação cruzada);\n","3. Compute o relatório de classificação com os dados de teste. "]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","model = LogisticRegression()\n","model.fit(x_train, y_train)\n","\n","print(\"Ein: \" + str(1 - accuracy_score(y_train, model.predict(x_train))))\n","print(\"Eout: \" + str(1 - accuracy_score(y_test, model.predict(x_test))))\n","print(classification_report(y_test, model.predict(x_test)))"],"metadata":{"id":"RAaMuQ0Z08NW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sentença final do artigo seminal de Dawes: \n","\n","**\"O segredo reside em decidir quais variáveis observar e depois saber como somar\".**\n","\n","**Atividade 5:**\n","\n","1. Implemente o classificador do modelo linear improprio. Todos os pesos de cada variável preditora são igual em módulo a 1, entretanto, toda variável com correlação negativa ao resutlado deve ter peso -1. Adicione o peso do bias igual a +1; \n","2. Compute e compare os valores de $E_{in}$ e $E_{out}$ (correlação de validação cruzada); \n","3. Computar o valor de acurácia dos dados de teste e comparar com o classificador das Atividades 4."],"metadata":{"id":"rGNFfi8sTm-r"}},{"cell_type":"code","source":["class LinearInappropriateRegression:\n","  def fit(self, X, y):\n","    self.w = np.array([+1, +1, -1, +1, -1, -1])\n","\n","  def predict(self, X):\n","    return [1 if (self.w[0] + self.w[1:].T @ x) >= 0 \n","            else -1 for x in X]\n","\n","\n","model = LinearInappropriateRegression()\n","model.fit(x_train, y_train)\n","\n","print(\"Ein: \" + str(1 - accuracy_score(y_train, model.predict(x_train))))\n","print(\"Eout: \" + str(1 - accuracy_score(y_test, model.predict(x_test))))\n","print(classification_report(y_test, model.predict(x_test)))"],"metadata":{"id":"3Zugjtu1Huig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Atividade 6:**\n","\n","1. Realizar o processo de validação do parâmetro *C* da penalidade $l_2$ (regularização *weight decay*) usando a classe *GridSearchCV* do pacote *sklearn.model_selection*;\n","2. Compute e compare os valores de $E_{in}$ e $E_{out}$ (validação cruzada); \n","3. Computar o valor de acurácia dos dados de teste e comparar com o classificador das Atividades 4.\n","\n","Parâmetros:\n","\n","\n","*   *estimator* : instância do classificador cujos hiperparâmetros serão analisados;\n","*   *cv* : número de divisões do conjunto de treinamento para ser usado na técnica de validação cruzada (10 é um bom valor observado na prática);\n","*   *param_grid* : conjunto de parâmetros a serem combinados durante a fase de validação."],"metadata":{"id":"dlmjuyhBcBin"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\"C\":np.logspace(-3,3,8)}\n","model = LogisticRegression(penalty='l2')\n","\n","clf = GridSearchCV(model, param_grid, cv=10)\n","clf.fit(x_train, y_train)\n","\n","print(\"Ein: \" + str(1 - accuracy_score(y_train, clf.predict(x_train))))\n","print(\"Eout: \" + str(1 - accuracy_score(y_test, clf.predict(x_test))))\n","print(classification_report(y_test, clf.predict(x_test)))"],"metadata":{"id":"aaupKOatQkmB"},"execution_count":null,"outputs":[]}]}